{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Dependecies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cut the Video into 30 Frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * total_frames // num_frames)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting Key Points on Hand Landmarks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change with the video data captured from the phone\n",
    "frames = extract_frames('video/A.mp4')\n",
    "keypoints_sequence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([lh, rh])\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for frame in frames:\n",
    "        _, results = mediapipe_detection(frame, holistic)\n",
    "        keypoints = extract_keypoints(results)\n",
    "        keypoints_sequence.append(keypoints)\n",
    "\n",
    "keypoints_sequence = np.array(keypoints_sequence)\n",
    "\n",
    "# Expand dimensions to match model's expected input (NEW input for ConvLSTM)\n",
    "keypoints_sequence = np.expand_dims(keypoints_sequence, axis=-1)  # Shape: (num_frames, keypoints_dim, 1)\n",
    "keypoints_sequence = np.expand_dims(keypoints_sequence, axis=-1)  # Shape: (num_frames, keypoints_dim, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted action: Bertemu\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../model/33Class_ConvLSTM_acc098_loss01_50seq.h5')\n",
    "\n",
    "# Kelas pada model\n",
    "actions = np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', \n",
    "                    'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', \n",
    "                    'U', 'V', 'W', 'X', 'Y', 'Z', 'Halo', 'Perkenalkan', \n",
    "                    'Nama', 'Saya', 'Senang', 'Bertemu', 'Kamu'])\n",
    "\n",
    "# Expand dimensions to match model's expected input\n",
    "keypoints_sequence = np.expand_dims(keypoints_sequence, axis=0)\n",
    "\n",
    "# Predict\n",
    "res = model.predict(keypoints_sequence)[0]\n",
    "predicted_action = actions[np.argmax(res)]\n",
    "\n",
    "print(f\"Predicted action: {predicted_action}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TEMP CODE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simpan 30 frame ke folder (untuk cek)\n",
    "\n",
    "note: kalo bisa semua 30 frame, tangannya udah di dalam frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 frames to frame-video-t\n"
     ]
    }
   ],
   "source": [
    "def extract_and_save_frames(video_path, output_folder, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * total_frames // num_frames)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_filename = os.path.join(output_folder, f'frame_{i + 1}.jpg')\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "        else:\n",
    "            print(f\"Failed to read frame {i}\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Saved {num_frames} frames to {output_folder}\")\n",
    "\n",
    "# Path ke video yang akan diekstrak\n",
    "video_path = 'video/C-pakeHP.mp4'\n",
    "\n",
    "# Nama folder output\n",
    "output_folder = 'frame-video'\n",
    "\n",
    "# Ekstrak dan simpan frame\n",
    "extract_and_save_frames(video_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frame 1 with landmarks to landmark-Bertemu\\frame_landmark_1.jpg\n",
      "Saved frame 2 with landmarks to landmark-Bertemu\\frame_landmark_2.jpg\n",
      "Saved frame 3 with landmarks to landmark-Bertemu\\frame_landmark_3.jpg\n",
      "Saved frame 4 with landmarks to landmark-Bertemu\\frame_landmark_4.jpg\n",
      "Saved frame 5 with landmarks to landmark-Bertemu\\frame_landmark_5.jpg\n",
      "Saved frame 6 with landmarks to landmark-Bertemu\\frame_landmark_6.jpg\n",
      "Saved frame 7 with landmarks to landmark-Bertemu\\frame_landmark_7.jpg\n",
      "Saved frame 8 with landmarks to landmark-Bertemu\\frame_landmark_8.jpg\n",
      "Saved frame 9 with landmarks to landmark-Bertemu\\frame_landmark_9.jpg\n",
      "Saved frame 10 with landmarks to landmark-Bertemu\\frame_landmark_10.jpg\n",
      "Saved frame 11 with landmarks to landmark-Bertemu\\frame_landmark_11.jpg\n",
      "Saved frame 12 with landmarks to landmark-Bertemu\\frame_landmark_12.jpg\n",
      "Saved frame 13 with landmarks to landmark-Bertemu\\frame_landmark_13.jpg\n",
      "Saved frame 14 with landmarks to landmark-Bertemu\\frame_landmark_14.jpg\n",
      "Saved frame 15 with landmarks to landmark-Bertemu\\frame_landmark_15.jpg\n",
      "Saved frame 16 with landmarks to landmark-Bertemu\\frame_landmark_16.jpg\n",
      "Saved frame 17 with landmarks to landmark-Bertemu\\frame_landmark_17.jpg\n",
      "Saved frame 18 with landmarks to landmark-Bertemu\\frame_landmark_18.jpg\n",
      "Saved frame 19 with landmarks to landmark-Bertemu\\frame_landmark_19.jpg\n",
      "Saved frame 20 with landmarks to landmark-Bertemu\\frame_landmark_20.jpg\n",
      "Saved frame 21 with landmarks to landmark-Bertemu\\frame_landmark_21.jpg\n",
      "Saved frame 22 with landmarks to landmark-Bertemu\\frame_landmark_22.jpg\n",
      "Saved frame 23 with landmarks to landmark-Bertemu\\frame_landmark_23.jpg\n",
      "Saved frame 24 with landmarks to landmark-Bertemu\\frame_landmark_24.jpg\n",
      "Saved frame 25 with landmarks to landmark-Bertemu\\frame_landmark_25.jpg\n",
      "Saved frame 26 with landmarks to landmark-Bertemu\\frame_landmark_26.jpg\n",
      "Saved frame 27 with landmarks to landmark-Bertemu\\frame_landmark_27.jpg\n",
      "Saved frame 28 with landmarks to landmark-Bertemu\\frame_landmark_28.jpg\n",
      "Saved frame 29 with landmarks to landmark-Bertemu\\frame_landmark_29.jpg\n",
      "Saved frame 30 with landmarks to landmark-Bertemu\\frame_landmark_30.jpg\n",
      "Saved all frames to landmark-Bertemu\n"
     ]
    }
   ],
   "source": [
    "def make_directory(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "def extract_frames(video_path, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * total_frames // num_frames)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                  connection_drawing_spec=mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                  connection_drawing_spec=mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "def save_landmarked_frames(frames, output_folder, holistic):\n",
    "    make_directory(output_folder)\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        frame_filename = os.path.join(output_folder, f'frame_landmark_{i + 1}.jpg')\n",
    "        cv2.imwrite(frame_filename, image)\n",
    "        print(f\"Saved frame {i + 1} with landmarks to {frame_filename}\")\n",
    "\n",
    "# Path ke video yang akan diekstrak\n",
    "video_path = 'video/A.mp4'\n",
    "\n",
    "# Nama folder output\n",
    "output_folder = 'landmark'\n",
    "\n",
    "# Ekstrak frame dari video\n",
    "frames = extract_frames(video_path, num_frames=30)\n",
    "\n",
    "# Deteksi dengan Mediapipe dan simpan gambar yang sudah ada landmark\n",
    "mp_holistic = mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "save_landmarked_frames(frames, output_folder, mp_holistic)\n",
    "print(f\"Saved all frames to {output_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signLanguage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
