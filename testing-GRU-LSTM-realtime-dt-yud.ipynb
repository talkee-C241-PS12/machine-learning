{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9kcOiEcM9hwT"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import tensorflow as tf\n","import mediapipe as mp\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Sz6Nm_P_9hwX"},"outputs":[],"source":["# Define\n","mp_holistic = mp.solutions.holistic # Holistic model\n","mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n","\n","# Fungsi untuk deteksi dengan Mediapipe\n","def mediapipe_detection(image, model):\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n","    image.flags.writeable = False                  # Image is no longer writeable\n","    results = model.process(image)                 # Make prediction\n","    image.flags.writeable = True                   # Image is now writeable\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n","\n","    return image, results\n","\n","# Draw hand connections\n","def draw_landmarks(image, results):\n","    if results.left_hand_landmarks:\n","        mp_drawing.draw_landmarks(\n","            image,\n","            results.left_hand_landmarks,\n","            mp_holistic.HAND_CONNECTIONS,\n","            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n","            connection_drawing_spec=mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n","        )\n","    if results.right_hand_landmarks:\n","        mp_drawing.draw_landmarks(\n","            image,\n","            results.right_hand_landmarks,\n","            mp_holistic.HAND_CONNECTIONS,\n","            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n","            connection_drawing_spec=mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n","        )\n","\n","# Fungsi untuk mengekstraksi keypoints\n","def extract_keypoints(results):\n","    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n","    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n","\n","    return np.concatenate([lh, rh])\n","\n","# Daftar class actions\n","actions = np.array(['A', 'B', 'C', 'D', 'E', 'F', \n","                    'G', 'H', 'I', 'J', 'K', 'L', \n","                    'M', 'N', 'O', 'P', 'Q', 'R', \n","                    'S', 'T', 'U', 'V', 'W', 'X', \n","                    'Y', 'Z', 'Halo', 'Perkenalkan', 'Nama',\n","                    'Saya', 'Senang', 'Bertemu', 'Kamu'])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"O5B42pAT9hwY"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}],"source":["model = tf.keras.models.load_model(\"33C_GRU_acc098_loss01_25seq_yud.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLXmmqu59hwZ","outputId":"05b888f7-2533-4d72-def8-d3f911436b9a"},"outputs":[],"source":["# Initialize variables\n","sequence = []\n","sentence = []\n","predictions = []\n","\n","threshold = 0.95\n","\n","state = 'countdown'\n","countdown_time = 3\n","display_time = 2\n","start_time = time.time()\n","\n","cap = cv2.VideoCapture(0)\n","mp_holistic = mp.solutions.holistic\n","\n","# Helper function to show countdown\n","def show_countdown(image, seconds_left):\n","    cv2.putText(image, f'Memulai prediksi dalam {seconds_left}..', (100, 250),\n","                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4, cv2.LINE_AA)\n","\n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    while cap.isOpened():\n","        # Read frame\n","        ret, frame = cap.read()\n","\n","        current_time = time.time()\n","\n","        if state == 'countdown':\n","            seconds_left = countdown_time - int(current_time - start_time)\n","            image = frame.copy()\n","            show_countdown(image, seconds_left)\n","\n","            if seconds_left <= 0:\n","                state = 'collecting'\n","                start_time = current_time\n","                sequence = []\n","\n","        elif state == 'collecting':\n","            # Perform detection\n","            image, results = mediapipe_detection(frame, holistic)\n","            draw_landmarks(image, results)\n","\n","            # Prediction logic\n","            keypoints = extract_keypoints(results)\n","            sequence.append(keypoints)\n","\n","            if len(sequence) == 30:\n","                res = model.predict(np.expand_dims(sequence, axis=0))[0]\n","\n","                print(actions[np.argmax(res)])\n","                predictions.append(np.argmax(res))\n","\n","                # Update sentence based on prediction\n","                if np.unique(predictions[-28:])[0] == np.argmax(res):\n","                    if res[np.argmax(res)] > threshold:\n","                        if len(sentence) > 0:\n","                            if actions[np.argmax(res)] != sentence[-1]:\n","                                sentence.append(actions[np.argmax(res)])\n","                        else:\n","                            sentence.append(actions[np.argmax(res)])\n","\n","                if len(sentence) > 5:\n","                    sentence = sentence[-5:]\n","\n","                state = 'displaying'\n","                start_time = current_time\n","\n","        elif state == 'displaying':\n","            # Display the prediction\n","            if len(sentence) > 0:\n","                cv2.putText(image, ' '.join(sentence), (3, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","\n","            if (current_time - start_time) > display_time:\n","                state = 'countdown'\n","                start_time = current_time\n","\n","        # Show the frame\n","        cv2.imshow('OpenCV Feed', image)\n","\n","        # Break gracefully\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["cap.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"bangkit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
